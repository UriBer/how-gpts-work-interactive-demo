import streamlit as st
import pandas as pd
from transformers import AutoTokenizer, AutoModel  # ×˜×•×¢×Ÿ ××ª ×”××•×“×œ ×•××ª ×”-tokenizer (×›×œ×™ ×œ×¤×™×¨×•×§ ×˜×§×¡×˜ ×œ×˜×•×§× ×™×)
import torch  # ×¡×¤×¨×™×™×ª ×¢×™×‘×•×“ ××ª××˜×™ ×œ××•×“×œ×™× ×©×œ ×œ××™×“×” ×¢××•×§×”
import numpy as np

# ×”×’×“×¨×ª ×¤×¨××˜×¨×™× ×›×œ×œ×™×™× ×œ××¤×œ×™×§×¦×™×”
st.set_page_config(page_title="GPT Interactive Demo", layout="centered")

# ×‘×•×—×¨ ×©×¤×” (×¢×‘×¨×™×ª ××• ×× ×’×œ×™×ª) ×•×©×•××¨ ×‘×–×™×›×¨×•×Ÿ ×–×× ×™ (session)
target_lang = st.radio("Select language | ×‘×—×¨ ×©×¤×”", ["English", "×¢×‘×¨×™×ª"])
st.session_state['lang'] = target_lang

# ×˜×•×¢×Ÿ ××ª ×”××•×“×œ ×•×”-tokenizer ×¤×¢× ××—×ª ×•××˜××•×Ÿ ××•×ª× ×œ×©×™××•×© ×¢×ª×™×“×™ (×—×•×¡×š ×–××Ÿ ×•×¢×•××¡)
@st.cache_resource
def load_tokenizer_and_model():
    tokenizer = AutoTokenizer.from_pretrained("./models/bert-base-multilingual-cased")
    model = AutoModel.from_pretrained("./models/bert-base-multilingual-cased")
    return tokenizer, model

tokenizer, model = load_tokenizer_and_model()

# ×”×’×“×¨×ª ××©×¤×˜ ×‘×¨×™×¨×ª ××—×“×œ ×‘×”×ª×× ×œ×©×¤×” ×©× ×‘×—×¨×”
default_sentence = "The GPT revolution" if target_lang == "English" else "×”××”×¤×›×” ×©×œ GPT"

# ×”×’×“×¨×ª ××©×ª× ×” ×œ×–×™×”×•×™ ×”×× ×‘×•×¦×¢×” ×§×¤×™×¦×” ××•×˜×•××˜×™×ª
if 'navigate' not in st.session_state:
    st.session_state['navigate'] = False

# ×›×•×ª×¨×ª ×œ××¤×œ×™×§×¦×™×”
st.title("ğŸ“š Step 1: How GPT Works" if target_lang == "English" else "ğŸ“š ×©×œ×‘ ×¨××©×•×Ÿ: ××™×š GPT ×¢×•×‘×“")

# ×ª×™××•×¨ ×›×œ×œ×™ ×§×¦×¨ ×¢×œ ×”×©×œ×‘ ×”×¨××©×•×Ÿ
st.markdown(
    "Let's explore how GPT processes language step-by-step." if target_lang == "English" else
    "×‘×•××• × ×‘×™×Ÿ ×™×—×“ ××™×š GPT ××¢×‘×“ ×©×¤×” ×©×œ×‘ ××—×¨×™ ×©×œ×‘."
)

# ×©×“×” ×œ×”×–× ×ª ××©×¤×˜ ×©× ×©××¨ ×‘-session
title_text = "âœï¸ Enter your sentence:" if target_lang == "English" else "âœï¸ ×”×›× ×¡ ××©×¤×˜ ×œ×‘×—×™×¨×”:"
st.subheader(title_text)
user_sentence = st.text_input("Sentence" if target_lang == "English" else "××©×¤×˜", value=default_sentence)
st.session_state['user_sentence'] = user_sentence

# ××¢×‘×¨ ××•×˜×•××˜×™ ×œ××¡×š 2 ×× ×–×• ×”×¤×¢× ×”×¨××©×•× ×”
if user_sentence and not st.session_state['navigate']:
    st.session_state['navigate'] = True
    st.switch_page("pages/02-self-attention.py")

# Tokenize and get embeddings
# Convert the input text into tokens (numbers) that the model can process
# ×”××¨ ××ª ×”×˜×§×¡×˜ ×œ×˜×•×§× ×™× (××–×”×™× ××¡×¤×¨×™×™×) ×¢×‘×•×¨ ×”××•×“×œ
inputs = tokenizer(user_sentence, return_tensors="pt", add_special_tokens=True)

# pt = PyTorch tensors â†’ ××¢×¨×›×™× ××¡×¤×¨×™×™× ×”××•×ª×××™× ×œ×œ××™×“×” ×¢××•×§×”
with torch.no_grad():  # ××¦×‘ ×œ×œ× ×—×™×©×•×‘×™ ×’×¨×“×™×× ×˜×™× (×—×•×¡×š ××©××‘×™× ×‘×”×¡×§×”)
    outputs = model(**inputs)  # ×”×¢×‘×¨ ××ª ×”×§×œ×˜ ×“×¨×š ×”××•×“×œ ×•×§×‘×œ ××ª ×”×¤×œ×˜

# Extract tokens and embeddings
# ×§×‘×œ ××ª ××–×”×™ ×”×˜×•×§× ×™× ×”××§×•×¨×™×™× ××ª×•×š ×”×§×œ×˜
# ×•×œ××—×¨ ××›×Ÿ ×”××¨ ××•×ª× ×œ×˜×§×¡×˜ ×§×¨×™× (××—×¨×•×–×•×ª ×˜×§×¡×˜)
token_ids = inputs["input_ids"][0]
tokens = tokenizer.convert_ids_to_tokens(token_ids)

# ×”××¨×” ×©×œ ×”×¤×œ×˜ ××”×©×›×‘×” ×”××—×¨×•× ×” ×œ×•×§×˜×•×¨×™× × ×•××¨×™×™× ×‘×¢×–×¨×ª numpy
# last_hidden_state ××™×™×¦×’ ××ª ×”-embedding ×©×œ ×›×œ ×˜×•×§×Ÿ ×‘×¤×œ×˜
embeddings = outputs.last_hidden_state[0].numpy()

# ×›×•×ª×¨×ª ×œ×§×˜×’×•×¨×™×™×ª ×”×”×˜××¢×•×ª
st.subheader("ğŸ§  Embeddings" if target_lang == "English" else "ğŸ§  ×™×™×¦×•×’×™× (Embedding)")

# ×”×¡×‘×¨ ××™×œ×•×œ×™ ×¢×œ ×”×˜×•×§× ×™× ×•×”××‘× ×” ×©×œ ×”××•×“×œ
if target_lang == "English":
    st.markdown("""
    Each token (word or part of a word) is represented as a vector of numbers. We show only 3 dimensions for simplicity.

    **Special tokens:**
    - `[CLS]` â€” Classification token: summarizes the entire sentence for downstream tasks.
    - `[SEP]` â€” Separator token: marks the end of input or separates segments.

    **Tokens with `##` prefix** are sub-word units â€” they indicate that the token is part of a word continued from the previous token.
    """)
else:
    st.markdown("""
    ×›×œ ×˜×•×§×Ÿ (×™×—×™×“×ª ×˜×§×¡×˜) ××™×•×¦×’ ×›×•×§×˜×•×¨ ××¡×¤×¨×™ ×©××ª××¨ ××ª ××©××¢×•×ª×•.
    ×œ×¦×•×¨×š ×”×¤×©×˜×” ×× ×• ××¦×™×’×™× ×›××Ÿ ×¨×§ 3 ×××“×™× ××ª×•×š ×”×•×§×˜×•×¨ ×”××œ×.

    **×¢×•×’× ×™ ×˜×•×§× ×™× ××™×•×—×“×™×:**
    - `[CLS]` â€” ×˜×•×§×Ÿ ×©××¨×›×– ××ª ×›×œ ××©××¢×•×ª ×”××©×¤×˜ (Classification token)
    - `[SEP]` â€” ×˜×•×§×Ÿ ×©××¡××Ÿ ×¡×•×£ ×§×œ×˜ ××• ××¤×¨×™×“ ×‘×™×Ÿ ××©×¤×˜×™×

    **×˜×•×§× ×™× ×©××ª×—×™×œ×™× ×‘Ö¾`##`** ×”× ×—×œ×§×™ ××™×œ×™×. ×–×” ××•××¨ ×©×”×˜×•×§×Ÿ ×”×•× ×”××©×š ×©×œ ××™×œ×” ×©×”×ª×—×™×œ×” ×‘×˜×•×§×Ÿ ×§×•×“×.
    """)

# ×™×¦×™×¨×ª ×˜×‘×œ×ª ×¤×œ×˜ ×”××¦×™×’×” ××ª ×©×œ×•×©×ª ×”×××“×™× ×”×¨××©×•× ×™× ××›×œ embedding
columns = ["Dim 1", "Dim 2", "Dim 3"] if target_lang == "English" else ["×××“ 1", "×××“ 2", "×××“ 3"]
emb_df = pd.DataFrame(embeddings[:, :3], columns=columns)  # ×™×¦×™×¨×ª DataFrame ××ª×•×š ×¨×©×™××ª ×”×•×§×˜×•×¨×™×
emb_df.insert(0, "Token" if target_lang == "English" else "×˜×•×§×Ÿ", tokens)  # ×”×•×¡×¤×ª ×¢××•×“×ª ×˜×•×§× ×™× ×‘×”×ª×—×œ×”

# ×”×¦×’×ª ×”×˜×‘×œ×” ×œ××©×ª××©
st.dataframe(emb_df)

# ×›×¤×ª×•×¨ ××¢×‘×¨ ×™×“× ×™ ×œ×©×œ×‘ ×”×‘×
if st.button("â¡ï¸ Next: Self-Attention" if target_lang == "English" else "â¡ï¸ ×”××©×š ×œ×©×œ×‘ ×”×§×©×‘ ×”×¢×¦××™"):
    st.switch_page("pages/02-self-attention.py")